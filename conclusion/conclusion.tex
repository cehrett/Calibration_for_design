\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{natbib}
\author{Carl Ehrett}
\title{Conclusion}



\begin{document}
	
\maketitle

\section{Benefits}

The research presented in the previous chapters addresses two distinct desiderata related to model-assisted design.
Firstly, there is the desideratum of undertaking model-assisted design in a way that accounts for all forms of uncertainty -- uncertainty due to the model inputs, uncertainty due to the stochastic nature of the objective function, and/or uncertainty due to observation error of the outputs.
All of these sources of uncertainty can be modeled and included in the Bayesian framework used to employ our methodology.
The resulting posterior distribution of the design inputs quantifies uncertainty as to what inputs could lead to optimal system behavior.
The corresponding posterior predictive distributions quantifies uncertainty as to that resulting system behavior, including uncertainty of the entire Pareto front of the system.
In contrast with approaches such as that of \citet{Olalotiti-Lawal2015}, who provide similar uncertainty quantification of design input settings using a distribution they contrive, our method provides the uncertainty in a posterior distribution that is directly dictated by what is known about the computer model itself, by one's prior knowledge about the appropriate design settings, and by the priorities of decision-makers.

Our method furthermore evades the need to be able to evaluate the objective function adaptively.
This requirement is a limitation shared by most other Bayesian optimization (BO) methods.
In this way, our method may be employed in scenarios where researchers are confined to the usage of pre-existing data sets, or in scenarios where the experimental design used for data-gathering must satisfy priorities other than that of engineering design.

Secondly, there is the desideratum of unifying procedures for calibration and design.
Typically these two tasks are undertaken separately; a model would be calibrated and then the calibrated model would be put to use for model-assisted design.
However, design priorities arise for models that stand in need of calibration, and wedding the frameworks for calibration and design allows for a single use of a dataset to satisfy both sets of goals.

\section{Summary of chapter two}

In chapter 2, we focused on model-assisted design, assuming there the possession of an already-calibrated computer model.
We there considered the problem of engineering design from the perspective of, and using tools from the field of, computer model calibration under uncertainty.
Specifically, we approached model-assisted design from the Bayesian framework for model calibration developed by \citet{Kennedy2001}, which we here refer to as KOH.
We used this approach to undertake model-assisted design on a multi-objective system, quantifying remaining uncertainty regarding the optimal values of the design inputs and the resulting model output.

To do this, we relied on a method we call Counterfactual Bayes.
Ordinarily, under KOH, one has access to a set of experimental observations that one uses to calibrate a model, so that the model output approximates those observations well.
In the case of design, we wish to induce the model output to be \textit{optimal}; we do not have access to any particular set of real experimental observations that are relevant to that goal.
However, we argued, we may apply the KOH framework to design by reasoning using hypothetical -- i.e.\ counterfactual -- observations which would only occur if the design settings \textit{were} optimal.
By selecting such \textit{target outcomes}, we are able to apply KOH and thereby discover distributions of design inputs that induce the model to approximate the hypothetical target outcomes.
Since the target outcomes could be observed only when the design settings are optimal, our posterior distributions of design inputs achieving the target outcomes are \textit{de facto} distributions of \textit{optimal} design inputs.
Thus we showed that KOH can be enlisted through Counterfactual Bayes as a powerful methodology for model-assisted design with quantification of all relevant uncertainty.
In our discussion we included guidance as to the appropriate choice of target outcomes.
Specifically, we demonstrated how, with little added computational cost, an initial ``rough estimate'' of the system Pareto front can be generated and used to select effective target outcomes.

To accommodate models of high computational expense, we employed GP surrogate models.
We offered guidance on the selection of prior distributions for model inputs and for GP hyperparameters, as there are some aspects of these choices that are particular to the use of KOH with target outcomes.
We then described an algorithm for the repeated application of our methodology in order to estimate not merely the optimal design settings with respect to some one goal, but instead to estimate the entire Pareto front for the system of interest.
This allows decision-makers full flexibility in selecting a design to meet any set of priorities.

We demonstrated our methodology on a simulated example, where we were able to display the results of the procedure using the known optimum of the system.
We also demonstrated our methodology, including the algorithm for full Pareto front estimation, on an application of material design for a wind turbine blade.
We included a comparison showing that our resulting estimated Pareto front agrees with an estimate provided by NSGA-II \citep{Deb2002}, and that our estimate (unlike that of NSGA-II) is able to provide credible bands quantifying uncertainty remaining in the Pareto front location.

We concluded that our method captures much of what is attractive in other BO methods, without requiring the ability to sample the objective function adaptively.
Our method thus is a useful addition to the set of tools available to a researcher wishing to undertake model-assisted multi-objective design under uncertainty.


\bibliographystyle{apalike}

\bibliography{lit_review}
	
\end{document}